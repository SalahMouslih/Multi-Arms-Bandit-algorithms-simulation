# Multi-Arms-Bandit-algorithms-simulation

This notebook provides an intuitive guide for the Multi-arms Bandit problem using the [SMPyBandits](https://smpybandits.github.io/docs/) library.

We provide a simulation using **Leader** and **UCB** algorithms which are the most common used algorithms in this problem as well as a graphical comparasion of their performances.
